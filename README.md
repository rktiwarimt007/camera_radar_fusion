# ğŸš— Cameraâ€“Radar Sensor Fusion for Real-Time Object Detection

![Python](https://img.shields.io/badge/Python-3.11-blue?style=flat-square&logo=python)
![YOLOv8](https://img.shields.io/badge/YOLOv8-Ultralytics-purple?style=flat-square)
![DeepSORT](https://img.shields.io/badge/Tracker-DeepSORT-orange?style=flat-square)
![KITTI](https://img.shields.io/badge/Dataset-KITTI-green?style=flat-square)
![License](https://img.shields.io/badge/License-MIT-yellow?style=flat-square)

A real-time multi-sensor perception pipeline that combines **YOLOv8 object detection** with **DeepSORT tracking**, **Kalman Filter state estimation**, and **simulated radar fusion** â€” replicating a simplified ADAS (Advanced Driver Assistance System) perception stack evaluated on the KITTI benchmark dataset.

---

## ğŸ“½ï¸ Demo

> Full pipeline running on KITTI sequence 0006 â€” real autonomous driving footage

![Pipeline Demo](outputs/demo.gif)

---

## ğŸ§  System Architecture

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Camera Frame   â”‚â”€â”€â”€â”€â–¶â”‚   YOLOv8 Detector    â”‚
â”‚  (KITTI / Cam)  â”‚     â”‚  Bounding Boxes +     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  Class + Confidence   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   DeepSORT Tracker   â”‚
                        â”‚  Persistent IDs +    â”‚
                        â”‚  Re-identification   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Radar Simulator â”‚â”€â”€â”€â”€â–¶â”‚    Sensor Fusion     â”‚
â”‚  Range + Radial â”‚     â”‚  Kalman Filter       â”‚
â”‚  Velocity +     â”‚     â”‚  Camera + Radar      â”‚
â”‚  Gaussian Noise â”‚     â”‚  Weighted Update     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚     Evaluation       â”‚
                        â”‚  Precision / Recall  â”‚
                        â”‚  F1 Score / RMSE     â”‚
                        â”‚  5-Panel Report      â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Features

- **YOLOv8n** real-time object detection â€” person, car, truck, bus, motorcycle
- **DeepSORT** multi-object tracking with persistent IDs across occlusions
- **Kalman Filter** state estimation using constant velocity motion model
- **Radar Simulation** with configurable Gaussian noise on range and radial velocity
- **Sensor Fusion** â€” confidence-weighted camera + radar Kalman update step
- **KITTI Dataset** support â€” real autonomous driving benchmark evaluation
- **Evaluation Metrics** â€” Precision, Recall, F1 Score, RMSE per frame
- **5-panel evaluation report** auto-saved on exit
- **Live velocity plot** updated in real time during inference
- **Output video** saved to `outputs/tracked_output.mp4`

---

## ğŸ“ State-Space Model

**State vector tracked per object:**

```text
X = [x,  y,  vx,  vy]áµ€
     pos     velocity
```

**Constant velocity motion model:**

```text
X_k = A Â· X_(k-1) + w_k

    | 1  0  dt  0 |
A = | 0  1  0  dt |
    | 0  0  1   0 |
    | 0  0  0   1 |

dt = time between frames (~0.033s at 30fps)
w_k = process noise
```

**Measurement sources:**

| Sensor            | Measurement                 | Noise Model              -|
|-------------------|-----------------------------| --------------------------|
| Camera (YOLO)     | position (x, y)             | Gaussian Ïƒ = 10 px        |
| Radar (simulated) | range r, radial velocity v  | Gaussian Ïƒ = 5.0, Ïƒ = 0.5 |

**Fusion update:**

```text
fused_vx = 0.4 Ã— camera_vx  +  0.6 Ã— radar_vx
fused_vy = 0.4 Ã— camera_vy  +  0.6 Ã— radar_vy
```

---

## ğŸ“ Project Structure

```text
camera_radar_fusion/
â”‚
â”œâ”€â”€ main.py                     # Pipeline entry point
â”œâ”€â”€ config.py                   # All configurable settings
â”œâ”€â”€ requirements.txt            # Full dependency snapshot
â”œâ”€â”€ requirements_clean.txt      # Minimal install dependencies
â”‚
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ detector.py             # YOLOv8 camera detection
â”‚   â”œâ”€â”€ tracker.py              # Kalman Filter tracker (basic)
â”‚   â”œâ”€â”€ deepsort_tracker.py     # DeepSORT tracker (upgraded)
â”‚   â”œâ”€â”€ radar.py                # Radar simulator with Gaussian noise
â”‚   â””â”€â”€ fusion.py               # Sensor fusion logic
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ metrics.py              # RMSE, Precision, Recall
â”‚   â”œâ”€â”€ visualizer.py           # Live velocity plot
â”‚   â”œâ”€â”€ evaluator.py            # Full 5-panel evaluation report
â”‚   â””â”€â”€ kitti_loader.py         # KITTI dataset loader
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ kitti/                  # KITTI sequences (not tracked by Git)
â”‚       â”œâ”€â”€ image_02/0006/      # 270 PNG frames
â”‚       â””â”€â”€ label_02/0006.txt   # Ground truth labels
â”‚
â””â”€â”€ outputs/
    â”œâ”€â”€ tracked_output.mp4      # Output demo video
    â”œâ”€â”€ evaluation_report.png   # 5-panel evaluation graph
    â””â”€â”€ velocity_plot.png       # Fused speed over time
```

---

## ğŸš€ Installation

1. Clone the repository

    ```bash
    git clone https://github.com/rktiwarimt007/camera_radar_fusion
    cd camera-radar-fusion
    ```

2. Create virtual environment

    ```bash
    # Windows
    python -m venv venv
    venv\Scripts\activate

    # Linux / Mac
    python -m venv venv
    source venv/bin/activate
    ```

3. Install dependencies

    ```bash
    pip install -r requirements_clean.txt
    ```

---

## ğŸ“¦ KITTI Dataset Setup

1. Download from ğŸ‘‰ [KITTI Tracking Benchmark](https://www.cvlibs.net/datasets/kitti/eval_tracking.php):
   - **Left color images** (tracking training set)
   - **Training labels**

2. Organize into:

    ```text
        data/kitti/image_02/0006/000000.png ...
        data/kitti/label_02/0006.txt
    ```

3. In `config.py` set:

    ```python
    USE_KITTI        = True
    KITTI_SEQUENCE   = "0006"
    ```

---

## â–¶ï¸ Usage

### Run on KITTI dataset

```bash
python main.py
```

### Run on webcam

In `config.py` set `USE_KITTI = False`, then:

```bash
python main.py
```

### Controls

| Key | Action                          |
|-----|---------------------------------|
| `q` | Quit and save evaluation report |

### Outputs saved automatically

```text
outputs/tracked_output.mp4       # annotated video
outputs/evaluation_report.png    # 5-panel metrics report
outputs/velocity_plot.png        # fused speed over time
```

---

## âš™ï¸ Configuration

All settings in `config.py`:

```python
# Detection
YOLO_MODEL            = "yolov8n.pt"     # n=fast, s/m=accurate
CONFIDENCE_THRESHOLD  = 0.5
TARGET_CLASSES        = [0, 2, 3, 5, 7]  # person, car, motorcycle, bus, truck

# Radar simulation
RADAR_MAX_RANGE       = 800              # pixels
RADAR_RANGE_NOISE     = 5.0              # Gaussian Ïƒ for range
RADAR_VELOCITY_NOISE  = 0.5             # Gaussian Ïƒ for velocity

# Fusion weights (must sum to 1.0)
FUSION_CAMERA_TRUST   = 0.4
FUSION_RADAR_TRUST    = 0.6

# Dataset
USE_KITTI             = True
KITTI_SEQUENCE        = "0006"
```

---

## ğŸ“Š Results

Evaluated on **KITTI Tracking Sequence 0006** (270 frames, real urban driving):

| Metric | Value |
|--------|-------|

| Total Frames | **270** |
| Avg Precision | **0.526** |
| Avg Recall | **0.596** |
| F1 Score | **0.559** |
| RMSE Velocity | **0.206 px/frame** |
| Total True Positives | **380** |
| Total False Positives | **129** |
| Total False Negatives | **27** |

> CPU inference only â€” YOLOv8n model â€” Windows 11

### Evaluation Report

![Evaluation Report](outputs/evaluation_report.png)

### Fused Speed Over Time

![Velocity Plot](outputs/velocity_plot.png)

---

## ğŸ¨ Visualization Legend

| Color | Meaning |
|-------|---------|

| ğŸŸ© Green box | Raw YOLO detection |
| ğŸ”µ Blue dot + line | Simulated radar measurement |
| ğŸŸ¡ Yellow ring | Sensor fusion active on object |
| Colored dot + trail | DeepSORT tracked object with history |
| Arrow | Estimated velocity direction |

---

## ğŸ›£ï¸ Roadmap

- [x] YOLOv8 real-time object detection
- [x] Kalman Filter state estimation
- [x] Simulated radar with Gaussian noise
- [x] Cameraâ€“radar sensor fusion
- [x] DeepSORT multi-object tracking
- [x] KITTI benchmark dataset support
- [x] Precision / Recall / F1 / RMSE evaluation
- [x] 5-panel evaluation report
- [ ] Hungarian algorithm for better assignment
- [ ] 3D bounding box estimation
- [ ] Real radar data integration (KITTI raw)
- [ ] Edge deployment on Jetson Nano / Raspberry Pi

---

## ğŸ§° Tech Stack

| Library | Version | Purpose |
|---------|---------|---------|

| ultralytics | 8.4.18 | YOLOv8 object detection |
| deep-sort-realtime | 1.3.2 | Multi-object tracking |
| filterpy | 1.4.5 | Kalman Filter |
| opencv-python | 4.13.0 | Video I/O + visualization |
| matplotlib | 3.10.8 | Evaluation graphs |
| numpy | 2.4.2 | Matrix operations |
| torch | 2.10.0 | Deep learning backend |

---

## ğŸ‘¤ Author

Rahul Kumar Tiwari

Built as a portfolio project demonstrating a complete ADAS perception stack â€” covering deep learning, probabilistic state estimation, sensor fusion, and real-world benchmark evaluation.

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” free to use, modify and distribute.

---

## â­ If this project helped you, please give it a star
